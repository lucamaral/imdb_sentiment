{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Trabalho.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94471057"
      },
      "source": [
        "### AUTOR: Lucas Amaral\n",
        "\n",
        "### Classificação de textos para análise de sentimentos\n",
        "\n",
        "Base de dados \n",
        "\n",
        "Instruções:\n",
        "- O objetivo deste trabalho é criar um modelo binário de aprendizado de máquina para classificação de textos. \n",
        "Para isso, será utilizado a base de dados [IMDb](http://ai.stanford.edu/~amaas/data/sentiment/), que consiste de dados textuais de críticas positivas e negativas de filmes\n",
        "- Uma vez treinado, o modelo deve ter uma função `predict` que recebe uma string como parâmetro e retorna o valor 1 ou 0, aonde 1 significa uma crítica positiva e 0 uma crítica negativa\n",
        "- O pré-processamento pode ser desenvolvidado conforme desejar (ex.: remoção de stopwords, word embedding, one-hot encoding, char encoding)\n",
        "- É preferível que seja empregado um modelo de recorrência (ex.: rnn, lstm, gru) para a etapa de classificação\n",
        "- Documente o código (explique sucintamente o que cada função faz, insira comentários em trechos de código relevantes)\n",
        "- **Atenção**: Uma vez treinado o modelo final, salve-o no diretório do seu projeto e crie uma célula ao final do notebook contendo uma função de leitura deste arquivo, juntamente com a execução da função `predict`\n",
        "\n",
        "Sugestões:\n",
        "- Explorar a base de dados nas células iniciais do notebook para ter um melhor entendimento do problema, distribuição dos dados, etc\n",
        "- Após desenvolver a estrutura de classificação, é indicado fazer uma busca de hiperparâmetros e comparar os resultados obtidos em diferentes situações\n",
        "\n",
        "Prazo de entrega:\n",
        "- 01-08-2021 às 23:59hs GMT-3\n",
        "\n",
        "Formato preferível de entrega:\n",
        "- Postar no portal Ava da disciplina o link do projeto no github (ou anexar o projeto diretamente no portal Ava)\n",
        "\n",
        "luann.porfirio@gmail.com"
      ],
      "id": "94471057"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:36:57.559764Z",
          "start_time": "2021-06-10T00:36:52.638020Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2577de36",
        "outputId": "378c2386-106e-4c52-9c1c-f918ac3caed1"
      },
      "source": [
        "!pip install torchtext"
      ],
      "id": "2577de36",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-10T00:50:27.424355Z",
          "start_time": "2021-06-10T00:49:16.448387Z"
        },
        "id": "907e3626"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "# Buscando dataset IMDB\n",
        "train_iter, test_iter = datasets.IMDB()\n",
        "train_sentiments, train_reviews = zip(*train_iter)\n",
        "test_sentiments, test_reviews = zip(*test_iter)"
      ],
      "id": "907e3626",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O7Auyq_0PKF"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Criando DataFrames pra facilitar as análises\n",
        "\n",
        "df_train = pd.DataFrame(columns = ['sentiment', 'review'])\n",
        "df_train.sentiment = train_sentiments\n",
        "df_train.review = train_reviews\n",
        "\n",
        "df_test = pd.DataFrame(columns = ['sentiment', 'review'])\n",
        "df_test.sentiment = test_sentiments\n",
        "df_test.review = test_reviews"
      ],
      "id": "-O7Auyq_0PKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "STtdAiAO01gL",
        "outputId": "c647d6d2-baf8-483f-ddc0-555091500230"
      },
      "source": [
        "# Exemplo de reviews\n",
        "\n",
        "df_train.head()"
      ],
      "id": "STtdAiAO01gL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>If only to avoid making this type of film in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>This film was probably inspired by Godard's Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                             review\n",
              "0       neg  I rented I AM CURIOUS-YELLOW from my video sto...\n",
              "1       neg  \"I Am Curious: Yellow\" is a risible and preten...\n",
              "2       neg  If only to avoid making this type of film in t...\n",
              "3       neg  This film was probably inspired by Godard's Ma...\n",
              "4       neg  Oh, brother...after hearing about this ridicul..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuGxe62_1MqL",
        "outputId": "64e0194f-fce8-4907-831e-5bbb7e733f7a"
      },
      "source": [
        "# Verificando quantidade de sentimentos positivos e negativos\n",
        "print(df_train.sentiment.value_counts())\n",
        "print(df_test.sentiment.value_counts())"
      ],
      "id": "LuGxe62_1MqL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos    12500\n",
            "neg    12500\n",
            "Name: sentiment, dtype: int64\n",
            "pos    12500\n",
            "neg    12500\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6QRb8Hd9pq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e228c24a-686b-4b3e-db3c-e51516897b7e"
      },
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Definindo tokenizer e stopwords\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = stopwords.words('english')\n",
        "print(stopword_list)"
      ],
      "id": "H6QRb8Hd9pq9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_9flKRt2VNb"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "\n",
        "# Funções para limpeza das reviews\n",
        "\n",
        "def encode_sentiment (df):\n",
        "  return df['sentiment'].apply(lambda x : 1 if x == 'pos' else 0)\n",
        "\n",
        "def reviews_cleaning (df):\n",
        "  return df['review'].apply(lambda x : review_cleaning(x))\n",
        "\n",
        "def review_cleaning (review):\n",
        "  review = clear_text(review)\n",
        "  review = remove_stopwords_review(review)\n",
        "  return review\n",
        "\n",
        "def clear_text(review):\n",
        "  text = review\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  text = soup.get_text()                   # Remover tags HTML\n",
        "  text = re.sub('\\[[^]]*\\]', '', text)     # Remover []\n",
        "  text = re.sub(r'[^a-zA-z0-9\\s]','',text) # Remover caracteres especiais\n",
        "  text = str(text).lower()                 # Lowercase\n",
        "  return text\n",
        "\n",
        "def remove_stopwords_review(review):\n",
        "  text = review\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "  filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "  filtered_text = ' '.join(filtered_tokens)    \n",
        "  return filtered_text\n",
        "\n",
        "def format_df(df):\n",
        "  df['sentiment'] = encode_sentiment(df)\n",
        "  df['review'] = reviews_cleaning(df)\n",
        "  return df"
      ],
      "id": "y_9flKRt2VNb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ekFFk13bI2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Limpeza das reviews de treino e teste\n",
        "\n",
        "df_test = format_df(df_test)\n",
        "df_train = format_df(df_train)\n",
        "# Separação das reviews de treino em treino e validação\n",
        "df_train, df_valid = train_test_split(df_train, test_size=0.1) \n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)"
      ],
      "id": "b0ekFFk13bI2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLN9PWRj6nLl",
        "outputId": "a8aa0575-2333-4525-d5c0-df406bc225ff"
      },
      "source": [
        "print(\"Qtd reviews de treino :\", len(df_train))\n",
        "print(\"Qtd reviews de validação :\",len(df_valid))\n",
        "print(\"Qtd reviews de teste :\", len(df_test))"
      ],
      "id": "VLN9PWRj6nLl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qtd reviews de treino : 22500\n",
            "Qtd reviews de validação : 2500\n",
            "Qtd reviews de teste : 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "en63aq3Q6P6y",
        "outputId": "cb437ca0-f463-4e81-cbed-13c3fd5e2f6f"
      },
      "source": [
        "df_train.head()"
      ],
      "id": "en63aq3Q6P6y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>mere fact still think movie decade later reall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>really wanted like film story ridicules dont w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>reading reviews film opinion high markers prob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>nutcracker always somewhat problematic ballet ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>championship game couple days away things new ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          1  mere fact still think movie decade later reall...\n",
              "1          0  really wanted like film story ridicules dont w...\n",
              "2          0  reading reviews film opinion high markers prob...\n",
              "3          0  nutcracker always somewhat problematic ballet ...\n",
              "4          0  championship game couple days away things new ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "s6H_1pWM6Rlj",
        "outputId": "c9e27e0c-1f1b-442e-c711-62b5a283a417"
      },
      "source": [
        "df_valid.head()"
      ],
      "id": "s6H_1pWM6Rlj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>marvelous cult film 1979 students vince lombar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>99 100 times producers lied teeth someone else...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>certainly consider exorcist horror classic adm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>footlight parade among best 1930s musical come...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>movie starts slow tapers watching hour seeing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          1  marvelous cult film 1979 students vince lombar...\n",
              "1          0  99 100 times producers lied teeth someone else...\n",
              "2          0  certainly consider exorcist horror classic adm...\n",
              "3          1  footlight parade among best 1930s musical come...\n",
              "4          0  movie starts slow tapers watching hour seeing ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hhmxVvCm6SaD",
        "outputId": "a6c068c3-1b97-4b2d-8284-67ec1b55c5c2"
      },
      "source": [
        "df_test.head()"
      ],
      "id": "hhmxVvCm6SaD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>love scifi willing put lot scifi moviestv usua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>worth entertainment value rental especially li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>totally average film semialright action sequen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>star rating saturday night friday night friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>first let say havent enjoyed van damme movie s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                             review\n",
              "0          0  love scifi willing put lot scifi moviestv usua...\n",
              "1          0  worth entertainment value rental especially li...\n",
              "2          0  totally average film semialright action sequen...\n",
              "3          0  star rating saturday night friday night friday...\n",
              "4          0  first let say havent enjoyed van damme movie s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrhZm6oEFvct"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Gerando uma lista com todas as reviews\n",
        "reviews = df_train.review.append(df_valid.review).append(df_test.review)\n",
        "\n",
        "# Criando uma lista de palavras utilizadas nas reviews\n",
        "words_list = ' '.join(reviews).split()\n",
        "\n",
        "# Criando mapeamento das palavras, palavra => indice\n",
        "counts = Counter(words_list)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)} "
      ],
      "id": "QrhZm6oEFvct",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "582oYVEGuiKe",
        "outputId": "99f963fe-17f0-4716-f6e9-5a6c09bf92d2"
      },
      "source": [
        "# Quantidade de palavras mapeadas\n",
        "print('Palavras mapeadas: ', len((vocab_to_int)))"
      ],
      "id": "582oYVEGuiKe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palavras mapeadas:  221639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktPdFAjZuHZC",
        "outputId": "f5e8e815-d2df-4af6-f473-36f540d957d2"
      },
      "source": [
        "# Testando o mapa\n",
        "test_review = \"really nice movie\"\n",
        "print([vocab_to_int[word] for word in test_review.split()])"
      ],
      "id": "ktPdFAjZuHZC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 219, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQGQZMKMEXVF"
      },
      "source": [
        "# Utilizando o mapa de palavra => indice para converter as reviews em lista de inteiros\n",
        "\n",
        "train_x = []\n",
        "for review in df_train.review:\n",
        "    train_x.append([vocab_to_int[word] for word in review.split()])\n",
        "\n",
        "test_x = []\n",
        "for review in df_test.review:\n",
        "    test_x.append([vocab_to_int[word] for word in review.split()])\n",
        "\n",
        "valid_x = []\n",
        "for review in df_valid.review:\n",
        "    valid_x.append([vocab_to_int[word] for word in review.split()])"
      ],
      "id": "zQGQZMKMEXVF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "6NtGp6JdDgqW",
        "outputId": "eae8ff30-2d28-4122-8246-185f724349e7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Histograma das palavras\n",
        "\n",
        "reviews_len = [len(i) for i in train_x + valid_x + test_x]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "pd.Series(reviews_len).describe()"
      ],
      "id": "6NtGp6JdDgqW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    50000.000000\n",
              "mean       119.815700\n",
              "std         90.041148\n",
              "min          3.000000\n",
              "25%         64.000000\n",
              "50%         89.000000\n",
              "75%        146.000000\n",
              "max       1429.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlaCjBanIwUg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Criando função de padding, para ajustar as reviews\n",
        "# As reviews com menos de 200 palavras, serão incrementadas com 0 até chegar 200 palavras\n",
        "# As reviews com mais de 200 palavras, serão cortadas para ficarem com 200 palavras\n",
        "\n",
        "def padding(reviews, review_len):\n",
        "    reviews_padding = np.zeros((len(reviews), review_len),dtype=int)\n",
        "    for i, review in enumerate(reviews):\n",
        "        if len(review) != 0:\n",
        "            reviews_padding[i, -len(review):] = np.array(review)[:review_len]\n",
        "    return reviews_padding"
      ],
      "id": "LlaCjBanIwUg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfimGc-eIx75"
      },
      "source": [
        "# Normalizando as reviews para terem 200 palavras (inteiros mapeados)\n",
        "\n",
        "review_len = 200\n",
        "train_x = padding(train_x, review_len)\n",
        "valid_x = padding(valid_x, review_len)\n",
        "test_x = padding(test_x, review_len)"
      ],
      "id": "PfimGc-eIx75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5iPYMcpj4tm",
        "outputId": "ba887d71-df27-440e-c446-0420a24c772f"
      },
      "source": [
        "# Verificando shapes das listas\n",
        "\n",
        "print(\"Shape de treino :\", train_x.shape)\n",
        "print(\"Shape de validação :\", valid_x.shape)\n",
        "print(\"Shape de teste :\", test_x.shape)"
      ],
      "id": "w5iPYMcpj4tm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape de treino : (22500, 200)\n",
            "Shape de validação : (2500, 200)\n",
            "Shape de teste : (25000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfsWbz-mZy3"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "# Criando Tensores e posteriormente dataloaders com as reviews formatadas e os sentimentos\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(df_train.sentiment.to_numpy()))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(df_valid.sentiment.to_numpy()))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(df_test.sentiment.to_numpy()))\n",
        "batch_size = 50\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle = True, batch_size = batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size)"
      ],
      "id": "bnfsWbz-mZy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqyEPvYOkuF9",
        "outputId": "8611da72-d24c-4c97-dc03-2a1d32c97ae3"
      },
      "source": [
        "# Verificando se o GPU está habilitado para execução mais rápida \n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('GPU Habilitado.')\n",
        "else:\n",
        "    print('GPU Desabilitado')"
      ],
      "id": "mqyEPvYOkuF9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Habilitado.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvIZrO3tuTAW"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo para previsão de sentimentos\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Criando um layer embeded, para diminuir a dimensionalidade das palavras\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Criando um layer LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # Criando um layer Dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        # Criando um layer Linear\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "        # Criando um último layer Sigmoid\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # Executando layer embeded\n",
        "        embeds = self.embedding(x)\n",
        "\n",
        "        # Executando layer LSTM\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # Executando layer dropout\n",
        "        out = self.dropout(lstm_out)\n",
        "\n",
        "        # Executando layer Linear\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        # Executando layer Sigmoid\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # Buscando último sigmoid gerado\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1]\n",
        "        \n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # Criando dois hidden layers com zeros\n",
        "\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "id": "DvIZrO3tuTAW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvAodGDqDTnA",
        "outputId": "b3f36864-177d-49a9-b9cd-21d1a7fe10b2"
      },
      "source": [
        "# Definindo Hiperparâmetros de treino\n",
        "vocab_size = len(vocab_to_int) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400 \n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "id": "gvAodGDqDTnA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(221640, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPMOCwASDT8b"
      },
      "source": [
        "# Definindo Learning rate\n",
        "lr=0.003\n",
        "\n",
        "# Loss e otimizador\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "id": "KPMOCwASDT8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBox7UX6kcaM",
        "outputId": "80073c3b-f576-4472-936c-f878806071cb"
      },
      "source": [
        "epochs = 5\n",
        "counter = 0\n",
        "\n",
        "if train_on_gpu:\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "\n",
        "# Treinamento\n",
        "for e in range(epochs):\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # Lotes de treino\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if train_on_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
        "        optimizer.step()\n",
        "\n",
        "        if counter % 100 == 0:\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if train_on_gpu:\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: \", e+1)\n",
        "            print(\"Step: \", counter)\n",
        "            print(\"Loss: \", loss.item())\n",
        "            print(\"Validation Loss: \", np.mean(val_losses))"
      ],
      "id": "TBox7UX6kcaM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "Step:  100\n",
            "Loss:  0.5989491939544678\n",
            "Validation Loss:  0.6132193696498871\n",
            "Epoch:  1\n",
            "Step:  200\n",
            "Loss:  0.6395872235298157\n",
            "Validation Loss:  0.5696607279777527\n",
            "Epoch:  1\n",
            "Step:  300\n",
            "Loss:  0.5339544415473938\n",
            "Validation Loss:  0.45608013212680815\n",
            "Epoch:  1\n",
            "Step:  400\n",
            "Loss:  0.42692306637763977\n",
            "Validation Loss:  0.39645756244659425\n",
            "Epoch:  2\n",
            "Step:  500\n",
            "Loss:  0.31391358375549316\n",
            "Validation Loss:  0.3816233882308006\n",
            "Epoch:  2\n",
            "Step:  600\n",
            "Loss:  0.40620946884155273\n",
            "Validation Loss:  0.3691871702671051\n",
            "Epoch:  2\n",
            "Step:  700\n",
            "Loss:  0.10581527650356293\n",
            "Validation Loss:  0.40914772540330885\n",
            "Epoch:  2\n",
            "Step:  800\n",
            "Loss:  0.27459919452667236\n",
            "Validation Loss:  0.33926439106464384\n",
            "Epoch:  2\n",
            "Step:  900\n",
            "Loss:  0.1476391702890396\n",
            "Validation Loss:  0.3249207952618599\n",
            "Epoch:  3\n",
            "Step:  1000\n",
            "Loss:  0.028659233823418617\n",
            "Validation Loss:  0.38554888978600504\n",
            "Epoch:  3\n",
            "Step:  1100\n",
            "Loss:  0.1433340460062027\n",
            "Validation Loss:  0.4049817118048668\n",
            "Epoch:  3\n",
            "Step:  1200\n",
            "Loss:  0.0323263481259346\n",
            "Validation Loss:  0.4574714061617851\n",
            "Epoch:  3\n",
            "Step:  1300\n",
            "Loss:  0.03934802487492561\n",
            "Validation Loss:  0.4971402531862259\n",
            "Epoch:  4\n",
            "Step:  1400\n",
            "Loss:  0.02451162040233612\n",
            "Validation Loss:  0.5445213475823403\n",
            "Epoch:  4\n",
            "Step:  1500\n",
            "Loss:  0.04172490909695625\n",
            "Validation Loss:  0.4933210963010788\n",
            "Epoch:  4\n",
            "Step:  1600\n",
            "Loss:  0.04927815869450569\n",
            "Validation Loss:  0.48925600737333297\n",
            "Epoch:  4\n",
            "Step:  1700\n",
            "Loss:  0.016217943280935287\n",
            "Validation Loss:  0.5151267001032829\n",
            "Epoch:  4\n",
            "Step:  1800\n",
            "Loss:  0.07724152505397797\n",
            "Validation Loss:  0.5154903793334961\n",
            "Epoch:  5\n",
            "Step:  1900\n",
            "Loss:  0.12317972630262375\n",
            "Validation Loss:  0.5928071537613868\n",
            "Epoch:  5\n",
            "Step:  2000\n",
            "Loss:  0.008671917021274567\n",
            "Validation Loss:  0.6250344556570053\n",
            "Epoch:  5\n",
            "Step:  2100\n",
            "Loss:  0.01953720673918724\n",
            "Validation Loss:  0.603866564631462\n",
            "Epoch:  5\n",
            "Step:  2200\n",
            "Loss:  0.02183239720761776\n",
            "Validation Loss:  0.5538533860445023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7sbrwxlgTV",
        "outputId": "252026e0-9930-4c1a-a366-a5356c32f722"
      },
      "source": [
        "# Lista para armazenar losses dos testes\n",
        "\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "# Testes\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if train_on_gpu:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    pred = torch.round(output.squeeze())\n",
        "    \n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "# Printando a Loss\n",
        "print(\"Teste Loss: \", np.mean(test_losses))\n",
        "\n",
        "# Verificando acurácia\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Teste Acurácia: \", test_acc)"
      ],
      "id": "GC7sbrwxlgTV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Teste Loss:  0.678227122604847\n",
            "Teste Acurácia:  0.83892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7DUEmAEm-S_"
      },
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "   \n",
        "    net.eval()\n",
        "    \n",
        "    # Tokenizar a review\n",
        "    test_review = review_cleaning(test_review)\n",
        "    test_ints = [[vocab_to_int[word] for word in test_review.split() if word in vocab_to_int.keys()]]\n",
        "    \n",
        "    # Padding da review\n",
        "    seq_length = sequence_length\n",
        "    features = padding(test_ints, seq_length)\n",
        "    \n",
        "    # Criando o tensor\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "      \n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if train_on_gpu:\n",
        "      feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # Executando Rede Neural\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # Valor predito\n",
        "    pred = torch.round(output.squeeze())\n",
        "    \n",
        "    return pred.item()"
      ],
      "id": "k7DUEmAEm-S_",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S30TFGl2lTJ"
      },
      "source": [
        "# Função para printar resultado\n",
        "def print_result(result):\n",
        "  if result == 1:\n",
        "    print(\"Review positiva\")\n",
        "  else:\n",
        "    print(\"Review negativa\")"
      ],
      "id": "4S30TFGl2lTJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ywax0knVel"
      },
      "source": [
        "# Salvando modelo\n",
        "path = \"/content/modelo_sentimento.pt\"\n",
        "torch.save(net.state_dict(), path)\n",
        "\n",
        "# Definindo Hiperparâmetros\n",
        "vocab_size = len(vocab_to_int) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400 \n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "# Carregando modelo\n",
        "model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.load_state_dict(torch.load(path))\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "id": "M_ywax0knVel",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2msg42EY6J6D",
        "outputId": "83ffa27a-e8c0-4883-f1b6-f7ab4c1e4307"
      },
      "source": [
        "# Exemplo de review negativa\n",
        "test_review_neg = 'The actors were terrible and the movie direction was awful'\n",
        "result = predict(model, test_review_neg)\n",
        "print_result(result)"
      ],
      "id": "2msg42EY6J6D",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review negativa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKEvO2pA63im",
        "outputId": "ca8a29a9-07e9-4eed-d86b-18f3fd780b48"
      },
      "source": [
        "# Exemplo de review positiva\n",
        "test_review_pos = 'Great movie, I didnt see a movie like that in years'\n",
        "result = predict(model, test_review_pos)\n",
        "print_result(result)"
      ],
      "id": "kKEvO2pA63im",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review positiva\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYU2muDc8EiP",
        "outputId": "b403f623-c632-4305-bde2-3cdb44e0241d"
      },
      "source": [
        "# Aplicando modelo em um dataset de tweets\n",
        "df_tweets = pd.read_csv(\"/content/Tweets.csv\")\n",
        "df_tweets = df_tweets[['airline_sentiment', 'text']]\n",
        "df_tweets = df_tweets[df_tweets.airline_sentiment != 'neutral']\n",
        "df_tweets.airline_sentiment.value_counts()"
      ],
      "id": "sYU2muDc8EiP",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IV20Zkr9A8S"
      },
      "source": [
        "# Executando modelo na base de tweets\n",
        "\n",
        "predicted = []\n",
        "for tweet in df_tweets.text[:50]:\n",
        "  result = predict(model, tweet)\n",
        "  predicted.append(result)\n",
        "\n",
        "actual = []\n",
        "for airline_sentiment in df_tweets.airline_sentiment[:50]:\n",
        "  actual.append(1 if airline_sentiment == 'positive' else 0)"
      ],
      "id": "5IV20Zkr9A8S",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlyhTpi964v",
        "outputId": "d0244b87-697d-4c11-bec8-4670f03ebbba"
      },
      "source": [
        "# Verificando a acurácia do modelo na base de tweets\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(actual, predicted)"
      ],
      "id": "SGlyhTpi964v",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}